{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "20_cifar10_classification_mc_and_vi.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aR_ls1Ci-nl"
      },
      "source": [
        "# Cifar10 classification case study with novel class\n",
        "\n",
        "**Goal:** In this notebook you will investigate which advantages Bayesian NNs can offer in a classification task. You will use train data from 9 of the 10 classes in the Cifar10 dataset to fit different three probabilistic NN.\n",
        "First you fit a \"traditional\" non-Bayesian NN and then you will fit two Bayesian NN, one via variational inference and one via dropout. You will compare the accuracy of the different NN on the 9 known classes. Further you will investigate and compare the uncertainties expressed by the NNs for both the known classes and unknown class. Finally you will use these uncertainties to detect novel classes and filter out uncertain predictions.\n",
        "\n",
        "**Usage:** The idea of the notebook is that you try to understand the provided code by running it, checking the output and playing with it by slightly changing the code and rerunning it.\n",
        "\n",
        "**Dataset:** You work with the Cifar10 dataset. You have 60'000 32x32 pixel color images of 10 classes (\"airplane\",\"automobile\",\"bird\",\"cat\",\"deer\",\"dog\",\"frog\",\"horse\",\"ship\",\"truck\"). You will delete all images from the class \"horse\" in the training dataset to simulate a novel class. Note that we keep the class \"horse\" in the test dataset.\n",
        "\n",
        "**Content:**\n",
        "* Load the Cifar10 dataset\n",
        "* Delete all images of the class \"horse\" from the training dataset\n",
        "* Split the train dataset into a train and validation dataset (60:40 split) \n",
        "* Fit a non-Bayesian NN \n",
        "* Fit a Bayesian NN via variational inference \n",
        "* Fit a Bayesian NN via dropout \n",
        "* Compare the  of the accuracy of the models on the known classes\n",
        "* Compare the  of the uncertainties of the models on the known and unknown classes\n",
        "* Use the uncertainties to filter uncertain predictions\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1lqurBf7gx_"
      },
      "source": [
        "# !pip install tensorflow==2.1.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTIuJnjS7Epo"
      },
      "source": [
        "# !pip install tensorflow_probability==0.8.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rE8KfEvxFxq9"
      },
      "source": [
        "#### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESl26w7xML1z"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "import urllib.request\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow_probability as tfp\n",
        "import tensorflow as tf\n",
        "\n",
        "%matplotlib inline\n",
        "plt.style.use('default')\n",
        "\n",
        "print(\"TFP Version\", tfp.__version__)\n",
        "print(\"TF  Version\",tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmemfmRxF0pt"
      },
      "source": [
        "In the next cell you disable the tensorflow eager mode. We need to do this because otherwise we would get errors for the variational inference NN and we  would not be able to turn on and off the dropout in the MC dropout NN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHzeQBbhcV3W"
      },
      "source": [
        "from tensorflow.python.framework.ops import disable_eager_execution\n",
        "disable_eager_execution()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APxoLqsjkM31"
      },
      "source": [
        "#### Loading and preparation of the dataset\n",
        "\n",
        "Let's load the cifar 10 dataset. It is already splited into a train and test dataset. To get a feeling for the dataset, you plot a random example of each class of the trainingset. You can see that the images are quite small and its not always easy to see the class on the image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHnWbEuDMzKv"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAqFwLxMPHQU"
      },
      "source": [
        "labels=np.array([\"airplane\",\"automobile\",\"bird\",\"cat\",\"deer\",\"dog\",\"frog\",\"horse\",\"ship\",\"truck\"])\n",
        "#sample image of each label\n",
        "np.random.seed(22)\n",
        "plt.figure(figsize=(20,20))\n",
        "for i in range(0,len(np.unique(y_train))):\n",
        "    rmd=np.random.choice(np.where(y_train==i)[0],1)\n",
        "    plt.subplot(1,10,i+1)\n",
        "    img=x_train[rmd]\n",
        "    plt.imshow(img[0,:,:,:])\n",
        "    plt.title(np.str(y_train[rmd][0][0])+ \": \" + labels[i], fontsize=16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQZdM-PHG2x2"
      },
      "source": [
        "To simualte a novel class, you will delete all images of the class \"horse\" from the traning dataset. Note that you do this only in the trainset, the test dataset stays the same. In the train dataset you will now have 9 classes with 5'000 images of every class, in total 45'000 images. This will be your traning dataset for the three models.   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Go4tZ3Xwf8Wc"
      },
      "source": [
        "y_train_no_horse=np.delete(y_train,np.where(y_train==7)[0])\n",
        "x_train_no_horse=np.delete(x_train,np.where(y_train==7)[0],axis=0)\n",
        "print(y_train_no_horse.shape)\n",
        "print(x_train_no_horse.shape)\n",
        "y_train_no_horse=np.array(pd.get_dummies(y_train_no_horse))\n",
        "labels_no_horse=np.array([\"airplane\",\"automobile\",\"bird\",\"cat\",\"deer\",\"dog\",\"frog\",\"ship\",\"truck\"])\n",
        "print(y_train_no_horse.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymY2h4GzLrQe"
      },
      "source": [
        "Now you split the new training dataset without the horses randomly into a train and validationset. You use a 60:40 ratio for the split, so you have 27'000 train images with 9 classes and 18'000 validation images with 9 classes. The test dataset has 10'000 images and 10 classes. Note that we have a novel (unknown) class \"horse\" in the testset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfTBvgg8SkiZ"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train_no_horse, y_train_no_horse, test_size=0.4, random_state=22)\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_val.shape)\n",
        "print(y_val.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)\n",
        "\n",
        "#Before training the NNs with the data, we normalize the data to be in the range between -1 and 1. \n",
        "x_train=((x_train/255)-0.5)*2\n",
        "x_val=((x_val/255)-0.5)*2\n",
        "x_test=((x_test/255)-0.5)*2\n",
        "\n",
        "x_test.min(), x_test.max()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVA0YHjvYlB_"
      },
      "source": [
        "## Non-Bayesian CNN\n",
        "\n",
        "In this section we use a CNN with two convolutional blocks, followed by maxpooling layers. You use 8 kernels with the size 3x3 in the first convolutional block and in the second block you use 16 kernels with the size 3x3. The maxpoolingsize is 2x2 pixels. After the feature extraction you use a flatten layer and do the classification with 3 fully connected layers. Because the training takes a lot of time, you will load an already trained CNN with the learning curve."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLOW7UPyYkKw"
      },
      "source": [
        "from tensorflow.keras.layers import Convolution2D,MaxPooling2D,Dropout,Flatten,Dense\n",
        "from tensorflow.keras import Sequential\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Convolution2D(8,kernel_size=(3,3),padding=\"same\", activation = 'relu',input_shape=(32,32,3)))\n",
        "model.add(Convolution2D(8,kernel_size=(3,3),padding=\"same\", activation = 'relu'))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(Convolution2D(16,kernel_size=(3,3),padding=\"same\", activation = 'relu'))\n",
        "model.add(Convolution2D(16,kernel_size=(3,3),padding=\"same\", activation = 'relu'))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(100, activation = 'relu'))\n",
        "model.add(Dropout((0.5)))\n",
        "model.add(Dense(100, activation = 'relu'))\n",
        "model.add(Dropout((0.5)))\n",
        "model.add(Dense(9, activation = 'softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# history=model.fit(x_train, y_train, \n",
        "#                     batch_size=128, \n",
        "#                     epochs=50,\n",
        "#                     verbose=1, \n",
        "#                     validation_data=(x_val, y_val)\n",
        "#                   )"
      ],
      "metadata": {
        "id": "RrlULScH_Hol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMB1B7hjYkFg"
      },
      "source": [
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/tensorchiefs/dl_book/master/data/history_baseline_cifar10.csv\", \"history_baseline_cifar10.csv\")\n",
        "history=np.loadtxt(\"history_baseline_cifar10.csv\",delimiter=\",\")\n",
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(history[:,0])\n",
        "plt.plot(history[:,1])\n",
        "plt.ylim(0, 1)\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='lower right')\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(history[:,2])\n",
        "plt.plot(history[:,3])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqwqWP8R4_6Y"
      },
      "source": [
        "# load trained weights of the model\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/tensorchiefs/dl_book/master/data/model_cifar10_weights.hdf5\", \"model_cifar10_weights.hdf5\")\n",
        "model.load_weights(\"model_cifar10_weights.hdf5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUxjKqbKPk07"
      },
      "source": [
        "## Variational Inference\n",
        "\n",
        "Now we will train a bayesian neural network via variational inference. We again use a CNN with two convolutional blocks, followed by maxpooling layers. The setting is the same as above.\n",
        "\n",
        "Note that every weight in the network is now sampled from a normal distribution. The normal distribution has two paramters and therefore we have almost doubled our paramters (we don't use a distribution for bias terms) in the network.  Because the training takes a lot of time, you will load an already trained CNN with the learning curve."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8AlHlwoPhDS"
      },
      "source": [
        "kernel_divergence_fn=lambda q, p, _: tfp.distributions.kl_divergence(q, p) / (x_train.shape[0] *1.0)\n",
        "\n",
        "model_vi = Sequential()\n",
        "model_vi.add(tfp.layers.Convolution2DFlipout(8,kernel_size=(3,3),padding=\"same\", activation = 'relu', kernel_divergence_fn=kernel_divergence_fn,input_shape=(32,32,3)))\n",
        "model_vi.add(tfp.layers.Convolution2DFlipout(8,kernel_size=(3,3),padding=\"same\", activation = 'relu', kernel_divergence_fn=kernel_divergence_fn))\n",
        "model_vi.add(tf.keras.layers.MaxPooling2D((2,2)))\n",
        "model_vi.add(tfp.layers.Convolution2DFlipout(16,kernel_size=(3,3),padding=\"same\", activation = 'relu', kernel_divergence_fn=kernel_divergence_fn))\n",
        "model_vi.add(tfp.layers.Convolution2DFlipout(16,kernel_size=(3,3),padding=\"same\", activation = 'relu', kernel_divergence_fn=kernel_divergence_fn))\n",
        "model_vi.add(tf.keras.layers.MaxPooling2D((2,2)))\n",
        "model_vi.add(tf.keras.layers.Flatten())\n",
        "model_vi.add(tfp.layers.DenseFlipout(100, activation = 'relu', kernel_divergence_fn=kernel_divergence_fn))\n",
        "model_vi.add(tfp.layers.DenseFlipout(100, activation = 'relu', kernel_divergence_fn=kernel_divergence_fn))\n",
        "model_vi.add(tfp.layers.DenseFlipout(9, activation = 'softmax', kernel_divergence_fn=kernel_divergence_fn))\n",
        "\n",
        "model_vi.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
        "model_vi.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdPiCuNkD6rO"
      },
      "source": [
        "In the next cell you can see that you get a different prediction for the same image, when you predict it multilple times. Everytime you sample each weight with the corresponding parameters and the prediction changes a bit. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YY5ZlcUHRBpC"
      },
      "source": [
        "for i in range(0,5):\n",
        "  print(model_vi.predict(x_train[0:1])[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PEf2fCj3cwk"
      },
      "source": [
        "# Training\n",
        "# Note that we trained longer for the VI methods, than for the MC Bayes\n",
        "# from  tensorflow.keras.callbacks import ModelCheckpoint\n",
        "# fp = \"vi_128_lrdefault_weights.{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
        "# cb = ModelCheckpoint(filepath=fp, monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=50)\n",
        "# history=model_vi.fit(x_train, y_train,validation_data=(x_val,y_val), batch_size=128,epochs=700,verbose=1, callbacks=[cb])\n",
        "# model_vi.save_weights('vi_128_lrdefault.hdf5')\n",
        "# import pickle\n",
        "# with open('model_vi_bs_128_lrdefault_hist.pickle', 'wb') as file_pi:\n",
        "#         pickle.dump(history.history, file_pi)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iR-fIVKM7EsV"
      },
      "source": [
        "# download and load weights of the model\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/tensorchiefs/dl_book/master/data/vi_128_lrdefault.hdf5\", \"vi_128_lrdefault.hdf5\")\n",
        "model_vi.load_weights(\"vi_128_lrdefault.hdf5\")\n",
        "\n",
        "# download the history\n",
        "import pickle\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/tensorchiefs/dl_book/master/data/model_vi_bs_128_lrdefault_hist.pickle\", \"model_vi_bs_128_lrdefault_hist.pickle\")\n",
        "with open('model_vi_bs_128_lrdefault_hist.pickle', 'rb') as f:\n",
        "    history = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-lrwTU13CmW"
      },
      "source": [
        "plt.figure(figsize=(12,5))\n",
        "plt.subplot(1,2,1)\n",
        "#plt.plot(history[:,0])\n",
        "plt.plot(history['accuracy'])\n",
        "plt.plot(history['val_accuracy'])\n",
        "plt.ylim(0, 1)\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='lower right')\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(history['loss'])\n",
        "plt.plot(history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='upper right')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXtF3hD4fGaB"
      },
      "source": [
        "## MC Dropout\n",
        "\n",
        "Now we will train a bayesian neural network via dropout. We again use a CNN with two convolutional blocks, followed by maxpooling layers. You use 8 kernels with the size 3x3 in the first convolutional block and in the second block you use 16 kernels with the size 3x3. The maxpoolingsize is 2x2 pixels. After the feature extraction you use a flatten layer and do the classification with 3 fully connected layers. \n",
        "\n",
        "The number of weights is the same as in the original network. \n",
        "\n",
        "Note that we added dropout before every layer now, also in the convolutional part.  Because the training takes a lot of time, you will load an already trained CNN with the learning curve."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mKre5K4eC_F"
      },
      "source": [
        "model_mc = Sequential()\n",
        "model_mc.add(Convolution2D(8,kernel_size=(3,3),padding=\"same\", activation = 'relu',input_shape=(32,32,3)))\n",
        "model_mc.add(Dropout((0.3)))\n",
        "model_mc.add(Convolution2D(8,kernel_size=(3,3),padding=\"same\", activation = 'relu'))\n",
        "model_mc.add(Dropout((0.3)))\n",
        "model_mc.add(MaxPooling2D((2,2)))\n",
        "model_mc.add(Convolution2D(16,kernel_size=(3,3),padding=\"same\", activation = 'relu'))\n",
        "model_mc.add(Dropout((0.3)))\n",
        "model_mc.add(Convolution2D(16,kernel_size=(3,3),padding=\"same\", activation = 'relu'))\n",
        "model_mc.add(Dropout((0.3)))\n",
        "model_mc.add(MaxPooling2D((2,2)))\n",
        "model_mc.add(Flatten())\n",
        "model_mc.add(Dense(100, activation = 'relu'))\n",
        "model_mc.add(Dropout((0.3)))\n",
        "model_mc.add(Dense(100, activation = 'relu'))\n",
        "model_mc.add(Dropout((0.3)))\n",
        "model_mc.add(Dense(9, activation = 'softmax'))\n",
        "\n",
        "model_mc.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
        "\n",
        "model_mc.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcKNxXNRFcJE"
      },
      "source": [
        "In the next few cells you define a funtion model_mc_pred, that gives the option to turn the dropout at test time on and off. If you set the learning_phase to 0 you turn the dropout at test time off and if you set it to 1, it on. When it is on, you get a different prediction for the same image in each run. This is because in each run different nodes are randomly deleted. To use it as a bayesian neural network we need to turn the dropout on also at test time.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L84cMARw7Es4"
      },
      "source": [
        "#### Getting mc dropout predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-_XAtOBdBqi"
      },
      "source": [
        "import tensorflow.keras.backend as K\n",
        "model_mc_pred = K.function([model_mc.input, K.learning_phase()], [model_mc.output])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_Qh_m3rde4B"
      },
      "source": [
        "#no dropout at test time\n",
        "for i in range(0,5):\n",
        "  print(model_mc_pred([x_train[0:1],0])[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxVGW_knowVu"
      },
      "source": [
        "#dropout at test time\n",
        "for i in range(0,5):\n",
        "  print(model_mc_pred([x_train[0:1],1])[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ch45yZrnfP0_"
      },
      "source": [
        "# history=model_mc.fit(x_train, y_train,validation_data=(x_val,y_val), batch_size=128,epochs=400,verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYxRKILJBpOB"
      },
      "source": [
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/tensorchiefs/dl_book/master/data/history_mc_cifar10.csv\", \"history_mc_cifar10.csv\")\n",
        "history=np.loadtxt(\"history_mc_cifar10.csv\",delimiter=\",\")\n",
        "plt.figure(figsize=(12,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(history[:,0])\n",
        "plt.plot(history[:,1])\n",
        "plt.ylim(0, 1)\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='lower right')\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(history[:,2])\n",
        "plt.plot(history[:,3])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmcDnvZl9ivH"
      },
      "source": [
        "# download and load weights of the model\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/tensorchiefs/dl_book/master/data/model_mc_cifar10_weights.hdf5\", \"model_mc_cifar10_weights.hdf5\")\n",
        "model_mc.load_weights(\"model_mc_cifar10_weights.hdf5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBqfSpLWhNNH"
      },
      "source": [
        "## Accuracy on the the known lables in the train set for all three models \n",
        "In this section you will calculate the accuracies and of all three models. For the non bayesian NN, you will predict every test image once and for the two bayesian NN, you will predict every image 50 times and then takes the mean of all predicted classes. \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9fsQMnMpRgz"
      },
      "source": [
        "Here you save the indices of the known and the unknown (horse) classes. You will use them later to evaluate the uncertainty measures."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvNbeGEtKcNb"
      },
      "source": [
        "known_idx=np.where(y_test!=7)[0]\n",
        "unknown_idx=np.where(y_test==7)[0]\n",
        "\n",
        "print(len(known_idx))\n",
        "print(len(unknown_idx))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ja_1L-xp-9u"
      },
      "source": [
        "#### Non-Bayesian prediction\n",
        "\n",
        "Here you predict the lables for the non-bayesian CNN and calculate the uncertainty measures. You calculate the nll and the entropy, note that there is no total standart deviation in the non-bayesian model, because the same image will always get the same prediction. This is also the reason why we don't need to predict the same image for multiple times."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-bOyOue0_hj"
      },
      "source": [
        "pred=model.predict(x_test)\n",
        "pred_max_p=np.max(pred,axis=1)\n",
        "entropy=np.array([-np.sum( pred[i] * np.log2(pred[i] + 1E-14)) for i in range(0,len(pred))])\n",
        "nll_=-np.log(pred_max_p)\n",
        "pred_labels=np.array([labels_no_horse[np.argmax(pred[i])] for i in range(0,len(pred))])\n",
        "true_labels=np.array([labels[y_test[i][0]] for i in range(0,len(y_test))])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R98YlXwe0_bS"
      },
      "source": [
        "test_acc_all=np.average(true_labels==pred_labels)\n",
        "test_acc_known=np.average(true_labels[known_idx]==pred_labels[known_idx])\n",
        "test_acc_all, test_acc_known"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1Wir0--sHbu"
      },
      "source": [
        "#### Bayesian VI prediction\n",
        "\n",
        "Here you predict the lables for the bayesian CNN via variational inferce and calculate the uncertainty measures. You predict the same image for 50 times and calculate the mean predicted probabilities, the nll, the entropy and total standart deviation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6TbLVK3lgNE"
      },
      "source": [
        "pred_vi=np.zeros((len(x_test),9))\n",
        "pred_max_p_vi=np.zeros((len(x_test)))\n",
        "pred_std_vi=np.zeros((len(x_test)))\n",
        "entropy_vi = np.zeros((len(x_test)))\n",
        "\n",
        "for i in tqdm(range(0,len(x_test))):\n",
        "  multi_img=np.tile(x_test[i],(50,1,1,1))\n",
        "  preds=model_vi.predict(multi_img)\n",
        "  pred_vi[i]=np.mean(preds,axis=0)#mean over n runs of every proba class\n",
        "  pred_max_p_vi[i]=np.argmax(np.mean(preds,axis=0))#mean over n runs of every proba class\n",
        "  pred_std_vi[i]= np.sqrt(np.sum(np.var(preds, axis=0)))\n",
        "  entropy_vi[i] = -np.sum( pred_vi[i] * np.log2(pred_vi[i] + 1E-14)) #Numerical Stability\n",
        "pred_labels_vi=np.array([labels_no_horse[np.argmax(pred_vi[i])] for i in range(0,len(pred_vi))])\n",
        "pred_vi_mean_max_p=np.array([pred_vi[i][np.argmax(pred_vi[i])] for i in range(0,len(pred_vi))])\n",
        "nll_vi=-np.log(pred_vi_mean_max_p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3bcP5__N5Oz"
      },
      "source": [
        "test_acc_all_vi=np.average(true_labels==pred_labels_vi)\n",
        "test_acc_known_vi=np.average(true_labels[known_idx]==pred_labels_vi[known_idx])\n",
        "test_acc_all_vi, test_acc_known_vi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiUPdpbisoH-"
      },
      "source": [
        "#### Bayesian MC prediction\n",
        "\n",
        "Here you predict the lables for the bayesian CNN via dropout and calculate the uncertainty measures. You predict the same image for 50 times and calculate the mean predicted probabilities, the nll, the entropy and total standart deviation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dbkFoc0PF-I"
      },
      "source": [
        "pred_mc=np.zeros((len(x_test),9))\n",
        "pred_max_p_mc=np.zeros((len(x_test)))\n",
        "pred_std_mc=np.zeros((len(x_test)))\n",
        "entropy_mc = np.zeros((len(x_test)))\n",
        "\n",
        "for i in tqdm(range(0,len(x_test))):\n",
        "  multi_img=np.tile(x_test[i],(50,1,1,1))\n",
        "  preds=model_mc_pred([multi_img,1])\n",
        "  pred_mc[i]= np.mean(preds,axis=1)\n",
        "  pred_max_p_mc[i]=np.argmax(np.mean(preds,axis=1))#mean over n runs of every proba class\n",
        "  pred_std_mc[i]= np.sqrt(np.sum(np.var(preds, axis=1)))\n",
        "  entropy_mc[i] = -np.sum( pred_mc[i] * np.log2(pred_mc[i] + 1E-14)) #Numerical Stability\n",
        "pred_labels_mc=np.array([labels_no_horse[np.argmax(pred_mc[i])] for i in range(0,len(pred_mc))])\n",
        "pred_mc_mean_max_p=np.array([pred_mc[i][np.argmax(pred_mc[i])] for i in range(0,len(pred_mc))])\n",
        "nll_mc=-np.log(pred_mc_mean_max_p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89WXRYdSPF4B"
      },
      "source": [
        "test_acc_all_mc=np.average(true_labels==pred_labels_mc)\n",
        "test_acc_known_mc=np.average(true_labels[known_idx]==pred_labels_mc[known_idx])\n",
        "test_acc_all_mc, test_acc_known_mc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jp_pBdOJt000"
      },
      "source": [
        "Let's look at the accuarcy on only the knowns and all the lables for all  three models. You cann see that the two bayesian models perform better than the non-bayesian model. Note that the mc-dropout model is the best model in this case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFTadf3lnbif"
      },
      "source": [
        "import pandas as pd\n",
        "pd.DataFrame(np.array([[test_acc_known,test_acc_known_vi,test_acc_known_mc],[test_acc_all,test_acc_all_vi,test_acc_all_mc]]), index=['test acc on known labels','test acc on all labels'],columns=['Non-Bayesian','VI','MC'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vh2CvHd9xQ_H"
      },
      "source": [
        "#### Predicted classes for the unknown class\n",
        "Now you will look a at the unknown class. What are the predicted classes for these images of the horses for each model?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFazJdW-R9gk"
      },
      "source": [
        "plt.figure(figsize=(12,5))\n",
        "plt.subplot(1,3,1)\n",
        "plt.bar(np.unique(pred_labels[unknown_idx],return_counts=True)[0],np.unique(pred_labels[unknown_idx],return_counts=True)[1])\n",
        "plt.xticks(rotation=45)\n",
        "plt.title(\"Non-Bayesian: horses predicted as:\")\n",
        "plt.ylim([0,450])\n",
        "\n",
        "plt.subplot(1,3,2)\n",
        "plt.bar(np.unique(pred_labels_vi[unknown_idx],return_counts=True)[0],np.unique(pred_labels_vi[unknown_idx],return_counts=True)[1])\n",
        "plt.xticks(rotation=45)\n",
        "plt.title(\"VI: horses predicted as:\")\n",
        "plt.ylim([0,450])\n",
        "\n",
        "plt.subplot(1,3,3)\n",
        "plt.bar(np.unique(pred_labels_mc[unknown_idx],return_counts=True)[0],np.unique(pred_labels_mc[unknown_idx],return_counts=True)[1])\n",
        "plt.xticks(rotation=45)\n",
        "plt.title(\"MC: horses predicted as:\")\n",
        "plt.ylim([0,450])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wg0yXPAHGng3"
      },
      "source": [
        "As you see in the plot barplot above, most of the horses were classified as deers, which kind of makes sense, because it is the most simlar class to horse. There are also a lot of classifications as dogs or cats.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMBRLqpJH-JM"
      },
      "source": [
        "#### Compare the predictions for a known and unknown image\n",
        "\n",
        "Let's compare the predictions of all three models, for a known and an unknown image. For the two bayesian neural network, you will predict the same image for \n",
        "50 times and look at the predictive distribution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNFhkloWTImi"
      },
      "source": [
        "x_test_known = x_test[known_idx]\n",
        "y_test_known = y_test[known_idx]\n",
        "\n",
        "x_test_unknown = x_test[unknown_idx]\n",
        "y_test_unknown = y_test[unknown_idx]\n",
        "\n",
        "np.random.seed(7681)\n",
        "random_sample_known=np.random.choice(range(0,len(x_test_known)),1)\n",
        "np.random.seed(2384)\n",
        "random_sample_unknown=np.random.choice(range(0,len(x_test_unknown)),1)\n",
        "\n",
        "plt.figure(figsize=(18,12))\n",
        "plt.subplot(4,3,1)\n",
        "plt.axis('off')\n",
        "plt.text(0.5,0.5, \"Input image\",fontsize=22,horizontalalignment='center')\n",
        "plt.subplot(4,3,2)\n",
        "plt.imshow(np.squeeze(np.array(((((x_test_known[random_sample_known])/2)+0.5)*255),dtype=\"uint8\")))\n",
        "plt.title(\"known class\",fontsize=25)\n",
        "plt.subplot(4,3,3)\n",
        "plt.imshow(np.squeeze(np.array(((((x_test_unknown[random_sample_unknown])/2)+0.5)*255),dtype=\"uint8\")))\n",
        "plt.title(\"unknown class\",fontsize=25)\n",
        "\n",
        "plt.subplot(4,3,4)\n",
        "plt.axis('off')\n",
        "plt.text(0.5,0.5, \"Non-Bayesian CNN\",fontsize=22,horizontalalignment='center')\n",
        "plt.subplot(4,3,5)\n",
        "plt.scatter(range(0,9),model.predict(x_test_known[random_sample_known]),c=\"blue\")\n",
        "plt.ylabel(\"P(class)\",fontsize=16)\n",
        "plt.xticks(range(0,9),labels=np.repeat(\" \",9))\n",
        "plt.ylim([0,1])\n",
        "plt.subplot(4,3,6)\n",
        "plt.scatter(range(0,9),model.predict(x_test_unknown[random_sample_unknown]),c=\"blue\")\n",
        "plt.xticks(range(0,9),labels=np.repeat(\" \",9))\n",
        "plt.ylim([0,1])\n",
        "\n",
        "plt.subplot(4,3,7)\n",
        "plt.axis('off')\n",
        "plt.text(0.5,0.5, \"Bayesian CNN via VI\",fontsize=22,horizontalalignment='center')\n",
        "plt.subplot(4,3,8)\n",
        "for i in range(0,50):\n",
        "  plt.scatter(range(0,9),model_vi.predict(x_test_known[random_sample_known]),c=\"blue\",alpha=0.2)\n",
        "plt.xticks(range(0,9),labels=np.repeat(\" \",9))\n",
        "plt.ylim([0,1])\n",
        "plt.ylabel(\"P(class)\",fontsize=16)\n",
        "plt.subplot(4,3,9)\n",
        "for i in range(0,50):\n",
        "  plt.scatter(range(0,9),model_vi.predict(x_test_unknown[random_sample_unknown]),c=\"blue\",alpha=0.2)\n",
        "plt.xticks(range(0,9),labels=np.repeat(\" \",9))\n",
        "plt.ylim([0,1])\n",
        "\n",
        "plt.subplot(4,3,10)\n",
        "plt.axis('off')\n",
        "plt.text(0.5,0.5, \"Bayesian CNN via dropout\",fontsize=22,horizontalalignment='center')\n",
        "plt.subplot(4,3,11)\n",
        "for i in range(0,50):\n",
        "  plt.scatter(range(0,9),model_mc_pred([x_test_known[random_sample_known],1]),c=\"blue\",alpha=0.2)\n",
        "plt.xticks(range(0,9),labels=labels_no_horse,fontsize=16)\n",
        "plt.xticks(rotation=90)\n",
        "plt.ylim([0,1])\n",
        "plt.ylabel(\"P(class)\",fontsize=16)\n",
        "plt.subplot(4,3,12)\n",
        "for i in range(0,50):\n",
        "  plt.scatter(range(0,9),model_mc_pred([x_test_unknown[random_sample_unknown],1]),c=\"blue\",alpha=0.2)\n",
        "plt.xticks(range(0,9),labels=labels_no_horse,fontsize=16)\n",
        "plt.xticks(rotation=90)\n",
        "plt.ylim([0,1])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1pdE2xPJFcG"
      },
      "source": [
        "When you look at the predictions for the unknown calls, you can see the two bayesian neural nets can express their uncertainty better than the non-bayesian net. All three work are quite certain about the known class as you can see in the predictive distributions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNwQ6ZJhPAKA"
      },
      "source": [
        "#### Compare the uncertainty measures for all known and unknown classes\n",
        "\n",
        "Let's compare the uncertainty measures for all images and all three models. Look at the distributions for the known and unknown class. Can you see a difference? You will look at the nll the total standard deviation and the entropy. Note that there is no total standard deviation for the non-bayesian network, because the prediction is always the same, even if you predict the same image for multiple times."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-MJHkqqngvK"
      },
      "source": [
        "##### Unknown and known classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gke6MQJz7Evd"
      },
      "source": [
        "def plot_hists(dist, title, xlabel, xlim=None):\n",
        "    plt.hist(dist[unknown_idx],bins=30, density=True,alpha = 0.7)\n",
        "    plt.hist(dist[known_idx],bins=30,  density=True,alpha = 0.7)\n",
        "    plt.title(title)\n",
        "    plt.legend(['unknown','known'])\n",
        "    plt.xlabel(xlabel)\n",
        "    if xlim != None:\n",
        "        plt.xlim(xlim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2ns7E9tsIes"
      },
      "source": [
        "plt.figure(figsize=(18,18))\n",
        "\n",
        "# Non-Bayesian\n",
        "plt.subplot(3,3,1)\n",
        "plot_hists(nll_, \"Non-Bayesian nll of max p\", \"NLL\", [-0.2,2])\n",
        "plt.subplot(3,3,2)\n",
        "plt.axis(\"off\")\n",
        "plt.subplot(3,3,3)\n",
        "plot_hists(entropy, \"Non-Bayesian entropy\", \"Entropy\", [-0.2,2])\n",
        "\n",
        "# VI\n",
        "plt.subplot(3,3,4)\n",
        "plot_hists(nll_vi, \"VI nll of max p\", \"NLL\", [-0.2,2])\n",
        "plt.subplot(3,3,5)\n",
        "plot_hists(pred_std_vi, \"VI std dev.\", \"std\", [-0.2,0.8])\n",
        "plt.subplot(3,3,6)\n",
        "plot_hists(entropy_vi, \"VI entropy\", \"Entropy\", [-0.2,3.2])\n",
        "\n",
        "# MC Methods\n",
        "plt.subplot(3,3,7)\n",
        "plot_hists(nll_mc, \"MC nll of max p\", \"NLL\", [-0.2,2])\n",
        "plt.subplot(3,3,8)\n",
        "plot_hists(pred_std_mc, \"MC std dev.\", \"std\", [-0.2,0.8])\n",
        "plt.subplot(3,3,9)\n",
        "plot_hists(entropy_mc, \"MC entropy\", \"Entropy\", [-0.2,3.2])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4_CuZynTFBP"
      },
      "source": [
        "As you can see there is a clear difference in the uncertainty measures between the known and unknown classes. We have lower uncertainties in the known than in the unknown classes. You can also see that the bayesian models are showing higher uncertainties."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-6z_hWHTJnO"
      },
      "source": [
        "## Use the uncertainty measures as filter\n",
        "\n",
        "In the next cells you will use the uncertainty measures as filter. You will sort the predicitons by the uncertainty measures and calcualte the accuracy on the n most certrain images. You will compare all three models based on this accuracy vs most certain images plot. To simplify the the sorting and plotting, we first define a the function plot_certainty_idx_filter. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8OjEiKFy7KG"
      },
      "source": [
        "def plot_certainty_idx_filter(nr_of_best,certainty_measure,prediction,color,linetype):\n",
        "  certainty_idx = np.argsort(certainty_measure.reshape(len(certainty_measure)))\n",
        "  acc_nbest = np.zeros((nr_of_best))\n",
        "  for j in (range(0,nr_of_best)):\n",
        "    acc_nbest[j]=np.average(prediction[certainty_idx[0:j+1]]==true_labels[certainty_idx[0:j+1]])\n",
        "  plt.plot(acc_nbest,c=color,linewidth=2,linestyle=linetype)\n",
        "  plt.ylim([0.5,1.05])\n",
        "  plt.ylabel('accuracy',fontsize=14)\n",
        "  plt.xlabel('Number of Examples taken',fontsize=14)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78i7kd-w2GzG"
      },
      "source": [
        "plt.figure(figsize=(20,18))\n",
        "plt.subplot(3,2,1)\n",
        "plot_certainty_idx_filter(5000,nll_,pred_labels,'black','solid')\n",
        "plot_certainty_idx_filter(5000,nll_vi,pred_labels_vi,'red','dashed')\n",
        "plot_certainty_idx_filter(5000,nll_mc,pred_labels_mc,'blue','dotted')\n",
        "plt.title('Model Accuracy using p_max and p_mean_max as a filter',fontsize=16)\n",
        "plt.legend(['Non-Bayesian', 'VI',\"MC\"], loc='upper right')\n",
        "\n",
        "plt.subplot(3,2,2)\n",
        "plot_certainty_idx_filter(10000,nll_,pred_labels,'black','solid')\n",
        "plot_certainty_idx_filter(10000,nll_vi,pred_labels_vi,'red','dashed')\n",
        "plot_certainty_idx_filter(10000,nll_mc,pred_labels_mc,'blue','dotted')\n",
        "plt.title('Model Accuracy using p_max and p_mean_max as a filter',fontsize=16)\n",
        "plt.legend(['Non-Bayesian', 'VI',\"MC\"], loc='upper right')\n",
        "\n",
        "plt.subplot(3,2,3)\n",
        "plot_certainty_idx_filter(5000,entropy,pred_labels,'black','solid')\n",
        "plot_certainty_idx_filter(5000,entropy_vi,pred_labels_vi,'red','dashed')\n",
        "plot_certainty_idx_filter(5000,entropy_mc,pred_labels_mc,'blue','dotted')\n",
        "plt.title('Model Accuracy using the entropy as a filter',fontsize=16)\n",
        "plt.legend(['Non-Bayesian', 'VI',\"MC\"], loc='upper right')\n",
        "\n",
        "plt.subplot(3,2,4)\n",
        "plot_certainty_idx_filter(10000,entropy,pred_labels,'black','solid')\n",
        "plot_certainty_idx_filter(10000,entropy_vi,pred_labels_vi,'red','dashed')\n",
        "plot_certainty_idx_filter(10000,entropy_mc,pred_labels_mc,'blue','dotted')\n",
        "plt.title('Model Accuracy using the entropy as a filter',fontsize=16)\n",
        "plt.legend(['Non-Bayesian', 'VI',\"MC\"], loc='upper right')\n",
        "\n",
        "plt.subplot(3,2,5)\n",
        "plot_certainty_idx_filter(5000,pred_std_vi,pred_labels_vi,'red','dashed')\n",
        "plot_certainty_idx_filter(5000,pred_std_mc,pred_labels_mc,'blue','dotted')\n",
        "plt.title('Model Accuracy using the total standard deviation as a filter',fontsize=16)\n",
        "plt.legend(['VI',\"MC\"], loc='upper right')\n",
        "\n",
        "plt.subplot(3,2,6)\n",
        "plot_certainty_idx_filter(10000,pred_std_vi,pred_labels_vi,'red','dashed')\n",
        "plot_certainty_idx_filter(10000,pred_std_mc,pred_labels_mc,'blue','dotted')\n",
        "plt.title('Model Accuracy using the total standard deviation as a filter',fontsize=16)\n",
        "plt.legend(['VI',\"MC\"], loc='upper right')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsPSgnEpUGtW"
      },
      "source": [
        "You see that both bayesian models outperform the non-bayesian model. This means the bayesian model are more appropriate when you want to have an uncertainty measures. Note again that the mc-dropout model is the best model also in this case."
      ]
    }
  ]
}